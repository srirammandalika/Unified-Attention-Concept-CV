# Unified Attention Concept for Foundational Computer Visions Tasks

## Abstract:
This paper proposes a new approach to image
classification by adding a custom attention module to a ResNet-18
backbone. We aim to improve accuracy and efficiency in image
classification tasks with advanced attention mechanisms. Our
work uniquely presents combining hierarchical attention, contextual relevance, temporal memory and dynamic neighbourhood
adaptation in one attention module. This boosts the feature representation capability of the baseline ResNet-18 model to capture
intricate patterns and spatial hierarchies in the image data. We
used a pre-trained ResNet-18 to extract feature maps, from the
ImageNet weights and then passed them through our proposed
attention module. The relevance scores were calculated based on
different attention mechanisms and enhanced the feature maps
for classification tasks. We experimented on the CIFAR-100 and
Stanford Cars datasets with data augmentation and normalization to improve model robustness and performance. The results
show significant improvement in classification performance with
the proposed attention module compared to the unsupervised
baseline ResNet-18 performance. Specifically, the model with an
attention module has higher training and test accuracy and lower
loss. This shows more efficient learning and better generalization
capabilities. Our approach not only improves the model accuracy
but also provides a scalable solution for other computer vision
tasks. Future work can extend this to other datasets and domains
and potentially have a broader impact in fields that require
detailed image analysis and classification. 



## For queries, 
Please contact - mc9991@srmist.edu.in
